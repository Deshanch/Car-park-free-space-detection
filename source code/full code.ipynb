{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to get the access to the googel drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to goto the directory where i stored the mask rcnn as in this code i use it for detection\n",
    "import os\n",
    "os.chdir(\"/content/drive/My Drive/auto_parking_projects/Mask_RCNN/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to save the files generated during the processing\n",
    "!mkdir saved_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # this is to get the calculations\n",
    "import matplotlib as pt # for plotting facilities\n",
    "import cv2 # for capture handling\n",
    "# these are from the rcnn\n",
    "import mrcnn.config \n",
    "import mrcnn.utils\n",
    "from mrcnn.model import MaskRCNN\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi # this is to check about the gpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the configurations\n",
    "class MaskRCNNConfig(mrcnn.config.Config):\n",
    "    NAME = \"coco_pretrained_model_config\"\n",
    "    IMAGES_PER_GPU = 1\n",
    "    GPU_COUNT = 1\n",
    "    NUM_CLASSES = 1 + 80  \n",
    "    DETECTION_MIN_CONFIDENCE = 0.6 #setted to 60%\n",
    "\n",
    "# Root dir --- this is the Mask_RCNN folder and in there mask_rcnn_coco.h5 present and do all the things in this folder\n",
    "ROOT_DIR = Path(\".\")\n",
    "#Trained model loc\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    mrcnn.utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "VIDEO_SOURCE = \"resources/parking_video.mp4\" # here is the videos and photos for the training are included and this folder should be in the root\n",
    "\n",
    "# configurations for the model\n",
    "model = MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=MaskRCNNConfig())\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "\n",
    "video_capture = cv2.VideoCapture(VIDEO_SOURCE) # getting the video captures using opencv\n",
    "\n",
    "parked_car_boxes = None\n",
    "free_space_frames = 0\n",
    "count = 0\n",
    "free_space = False\n",
    "\n",
    "def get_car_boxes(boxes, class_ids):\n",
    "    # when detecting objects related to any of the classes are sent to this and purpose of this function is returning \n",
    "    # the boxes related to the class_ids[3,8,6] which are related to vehicles\n",
    "    car_boxes = []\n",
    "    # here what come is any type of object and from here we only get the bounding boxes for only vehicles\n",
    "    for i, box in enumerate(boxes):\n",
    "        if class_ids[i] in [3, 8, 6]:\n",
    "            car_boxes.append(box)\n",
    "    return np.array(car_boxes)\n",
    "\n",
    "while video_capture.isOpened():\n",
    "    success, frame = video_capture.read()# if read the capture one then it is succesful or not and the frame(=image) taken\n",
    "    \n",
    "    if not success:\n",
    "        print(\"couldn't read video\")\n",
    "        break\n",
    "        \n",
    "    elif count<80:\n",
    "        # by increasing and decreasing the checking counter value we can tune the place where the green box is placed\n",
    "        # this counter is to get the time gap that we are checking the free space of the park\n",
    "        success, frame2 = video_capture.read() #this is to get another read and compare the motion of vehicles\n",
    "        # --------------------------------------------------------------------------------------------------------------------------------------\n",
    "        # this set of codes is used to track moving objects -- to get an idea of these functions prefer some documentations\n",
    "        # --------------------------------------------------------------------------------------------------------------------------------------\n",
    "        d = cv2.absdiff(frame, frame2)# then get the absolute difference of two frames to identify the differences of pixels\n",
    "        grey = cv2.cvtColor(d, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(grey, (1, 1), 0)\n",
    "        ret, th = cv2.threshold( blur, 20, 255, cv2.THRESH_BINARY)\n",
    "        #morphological operations to remove the unnecessary parts in the getting processed image\n",
    "        dilated = cv2.dilate(th, np.ones((10, 10), np.uint8), iterations=1 )\n",
    "        eroded = cv2.erode(dilated, np.ones((10, 10), np.uint8), iterations=1 )\n",
    "        #fill the contours for even a better morphing of the vehicle\n",
    "        c, h = cv2.findContours(eroded, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)# c-contour h-hierachy \n",
    "        # contour is taken and it is applied to original image and get the moving object only one object is getting the the contour in one image\n",
    "        frame2 = cv2.drawContours(frame2, c, -1, (0,0,0), cv2.FILLED)\n",
    "        # --------------------------------------------------------------------------------------------------------------------------------------\n",
    "        if count%5 == 0:\n",
    "            # from every 5 time show the images with contours for the cars which are moving\n",
    "            print(\"Current frame counter\" + str(count))\n",
    "            pt.pyplot.imshow(frame2)\n",
    "            pt.pyplot.show()\n",
    "        \n",
    "        count = count + 1# moving object detection is happen for 40\n",
    "        continue\n",
    "    \n",
    "    rgb_image = frame[:, :, ::-1] # this is how convert gbr to rgb(opencv use gbr but to feed to mrcnn use rgb)\n",
    "    # The r variable will now have the results of detection:\n",
    "    # - r['rois'] are the bounding box of each detected object\n",
    "    # - r['class_ids'] are the class id (type) of each detected object\n",
    "    if parked_car_boxes is None:\n",
    "        # this happens for the very first time after 40 times--- for first frame getting the initial places of cars\n",
    "        results = model.detect([rgb_image], verbose=0)# then given to the model\n",
    "        r = results[0]\n",
    "        # This is the first frame of video - assume all the cars detected are in parking spaces.\n",
    "        # Save the location of each car as a parking space box and go to the next frame of video.\n",
    "        parked_car_boxes = get_car_boxes(r['rois'], r['class_ids'])\n",
    "          \n",
    "    elif count%200 == 0 and len(parked_car_boxes) != 0:\n",
    "        # get the places where the cars are located\n",
    "        results = model.detect([rgb_image], verbose=0)# then given to the model\n",
    "        r = results[0]\n",
    "        car_boxes = get_car_boxes(r['rois'], r['class_ids'])\n",
    "\n",
    "        # then take the previous one and compare the overlapping with it\n",
    "        overlaps = mrcnn.utils.compute_overlaps(parked_car_boxes, car_boxes)\n",
    "\n",
    "        # for every parking area\n",
    "        for parking_area, overlap_areas in zip(parked_car_boxes, overlaps):\n",
    "\n",
    "            #picrure ivided into parts and take the overlap therefore it sends array\n",
    "            max_IoU_overlap = np.max(overlap_areas)\n",
    "\n",
    "            # at every time get the the area of parking place of the car\n",
    "            y1, x1, y2, x2 = parking_area\n",
    "\n",
    "            # if there is no car in that place where there was a car before\n",
    "            if max_IoU_overlap < 0.15:\n",
    "                # if there is no vehicle in that car slot then draw a box around it in green color\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "                free_space = True\n",
    "            else:\n",
    "                # if there is a vehicle in that slot then draw a box of red color\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 1)\n",
    "\n",
    "            # Write the IoU measurement inside the box -- just opencv\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, f\"{max_IoU_overlap:0.2}\", (x1 + 6, y2 - 6), font, 0.3, (255, 255, 255))\n",
    "\n",
    "        # If a space has been free for several frames, pretty sure it is really free\n",
    "        if free_space:\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, f\"PARKING SLOT IS AVAILABEL!\", (10, 150), font, 3.0, (0, 255, 0), 2, cv2.FILLED)\n",
    "\n",
    "    #saving each frame\n",
    "    name = str(count) + \".jpg\"\n",
    "    name = os.path.join('./saved_images', name)\n",
    "    cv2.imwrite(name, frame)\n",
    "    count+=1\n",
    "    \n",
    "    #'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "print(\"Video finished\")\n",
    "video_capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# this code is usually for creating a video from set of photos\n",
    "images = list(glob.iglob(os.path.join('./saved_images', '*.*')))\n",
    "images = sorted(images, key=lambda x: float(os.path.split(x)[1][:-3]))\n",
    "\n",
    "def make_video(outvid, images=None, fps=30, size=None,is_color=True, format=\"FMP4\"):\n",
    "   \n",
    "    from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n",
    "    fourcc = VideoWriter_fourcc(*format)\n",
    "    vid = None\n",
    "    for image in images:\n",
    "        if not os.path.exists(image):\n",
    "            raise FileNotFoundError(image)\n",
    "        img = imread(image)\n",
    "        if vid is None:\n",
    "            if size is None:\n",
    "                size = img.shape[1], img.shape[0]\n",
    "            vid = VideoWriter(outvid, fourcc, float(fps), size, is_color)\n",
    "        if size[0] != img.shape[1] and size[1] != img.shape[0]:\n",
    "            img = resize(img, size)\n",
    "        vid.write(img)\n",
    "    vid.release()\n",
    "    return vid\n",
    "  \n",
    "make_video('./detecting.mp4', images, fps=30) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
